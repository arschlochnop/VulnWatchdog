from datetime import datetime, timezone, timedelta
import json
import os
import time
import traceback
from config import get_config
from libs.utils import search_github, get_cve_info, ask_gpt, search_searxng, get_github_poc, write_to_markdown, get_latest_commit_sha
from libs.webhook import send_webhook
from libs.gpt_analyzer import GPTAnalyzer  # æ–°å¢: GPTåˆ†æå™¨
from libs.blacklist_manager import BlacklistManager  # æ–°å¢: é»‘åå•ç®¡ç†å™¨
from models.models import get_db, CVE, Repository
import logging
import sys
from typing import List, Dict, Optional

# é…ç½®æ—¥å¿—
log_level = logging.DEBUG if get_config('DEBUG') == 'DEBUG' else logging.INFO
logging.basicConfig(
    level=log_level,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# è®¾ç½®ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«ï¼Œé¿å…è¾“å‡ºè¿‡å¤šDEBUGæ—¥å¿—
logging.getLogger('urllib3').setLevel(logging.WARNING)
logging.getLogger('urllib3.connectionpool').setLevel(logging.WARNING)

# ä»é…ç½®æ–‡ä»¶åŠ è½½åŠŸèƒ½å¼€å…³
enable_gpt = get_config('ENABLE_GPT')
enable_notify = get_config('ENABLE_NOTIFY')
enable_search = get_config('ENABLE_SEARCH')
enable_extended = get_config('ENABLE_EXTENDED')
enable_update_check = get_config('ENABLE_UPDATE_CHECK')
enable_cve_dedup = get_config('ENABLE_CVE_DEDUP')
enable_update_notify = get_config('ENABLE_UPDATE_NOTIFY')

# åˆå§‹åŒ– GPT åˆ†æå™¨
gpt_analyzer = None
if enable_gpt:
    try:
        gpt_analyzer = GPTAnalyzer(
            api_key=get_config('GPT_API_KEY'),
            api_url=get_config('GPT_SERVER_URL'),
            model=get_config('GPT_MODEL'),
            max_cve_info_chars=get_config('MAX_CVE_INFO_CHARS'),
            max_search_chars=get_config('MAX_SEARCH_CHARS'),
            max_poc_code_chars=get_config('MAX_POC_CODE_CHARS')
        )
        logger.info("âœ“ GPTåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
    except ValueError as e:
        logger.error(f"âœ— GPTåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        enable_gpt = False

# åˆå§‹åŒ–é»‘åå•ç®¡ç†å™¨
blacklist_manager = None
try:
    blacklist_manager = BlacklistManager()
    logger.info("âœ“ é»‘åå•ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    logger.error(f"âœ— é»‘åå•ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    blacklist_manager = None


def process_cve(cve_id: str, repo: Dict, engine, notified_cves_today: set) -> Dict:
    """
    å¤„ç†å•ä¸ªCVEä¿¡æ¯
    
    Args:
        cve_id: CVEç¼–å·
        repo: ä»“åº“ä¿¡æ¯
        engine: æ•°æ®åº“è¿æ¥
    """
    result = {}
    try:
        # æå–ä»“åº“åŸºæœ¬ä¿¡æ¯
        repo_pushed_at = repo.get('pushed_at', '')
        repo_link = repo.get('html_url', '')
        repo_name = repo.get('name', '')
        repo_description = repo.get('description', '')
        repo_full_name = repo.get('full_name', '')

        logger.info(f"å¼€å§‹å¤„ç†ä»“åº“: {repo_full_name}")

        # é»‘åå•æ£€æŸ¥
        if blacklist_manager:
            allowed, reason = blacklist_manager.check_repository(repo)
            if not allowed:
                logger.warning(f"âš« ä»“åº“å·²è¢«é»‘åå•æ‹¦æˆª: {repo_full_name} - {reason}")
                return result

        # æ£€æŸ¥ä»“åº“æ˜¯å¦å·²å­˜åœ¨
        repo_data = engine.query(Repository).filter(Repository.github_id == repo['id']).order_by(Repository.id.desc()).first()

        if repo_data:
            logger.info(f"ä»“åº“å·²å­˜åœ¨: {repo_link}")

            # å¯ç”¨æ›´æ–°æ£€æµ‹
            if enable_update_check:
                # é€šè¿‡commit SHAåˆ¤æ–­æ˜¯å¦æœ‰æ›´æ–°
                latest_sha = get_latest_commit_sha(repo_link)

                if not latest_sha:
                    logger.warning(f"æ— æ³•è·å–commit SHA,è·³è¿‡å¤„ç†: {repo_link}")
                    return result

                if repo_data.latest_commit_sha == latest_sha:
                    logger.info(f"ä»“åº“æ— æ›´æ–° (SHAç›¸åŒ: {latest_sha[:8]}...),è·³è¿‡å¤„ç†")
                    return result
                else:
                    logger.info(f"ä»“åº“æœ‰æ›´æ–° (æ—§SHA: {repo_data.latest_commit_sha[:8] if repo_data.latest_commit_sha else 'None'}... â†’ æ–°SHA: {latest_sha[:8]}...)")
                    action_log = 'update'
            else:
                # æœªå¯ç”¨æ›´æ–°æ£€æµ‹,ç›´æ¥è·³è¿‡å·²å­˜åœ¨çš„ä»“åº“
                logger.info(f"æ›´æ–°æ£€æµ‹æœªå¯ç”¨,è·³è¿‡å·²å­˜åœ¨çš„ä»“åº“")
                return result
        else:
            logger.info(f"å‘ç°æ–°ä»“åº“: {repo_link}")
            action_log = 'new'
            latest_sha = None  # æ–°ä»“åº“,ç¨åè·å–SHA

        # è·å–POCä»£ç 
        logger.info(f"è·å–POCä»£ç : {repo_link}")
        code_prompt = get_github_poc(repo_link)
        if not code_prompt:
            logger.error(f"è·å–POCä»£ç å¤±è´¥")
            return

        # è·å–æˆ–åˆ›å»ºCVEä¿¡æ¯
        cve = engine.query(CVE).filter(CVE.cve_id == cve_id).first()
        if not cve:
            logger.info(f"è·å–CVEä¿¡æ¯: {cve_id}")
            cve_info = get_cve_info(cve_id)
            if not cve_info:
                logger.error(f"è·å–CVEä¿¡æ¯å¤±è´¥")
                cve_info = {}
            else:    
                try:
                    cve_data = CVE(
                        cve_id=cve_id,
                        title=cve_info.get('title'),
                        description=cve_info.get('description',{}).get('value'),
                        cve_data=cve_info
                    )
                    engine.add(cve_data)
                    engine.commit()
                    logger.info(f"ä¿å­˜CVEä¿¡æ¯æˆåŠŸ")
                except Exception as e:
                    logger.error(f"ä¿å­˜CVEä¿¡æ¯å¤±è´¥: {str(e)}")
                    engine.rollback()
                
        else:
            cve_info = cve.cve_data
        result['cve'] = cve_info
        result['repo'] = repo

        # GPTåˆ†æ (ä½¿ç”¨æ–°çš„ GPTAnalyzer)
        gpt_results = None
        if enable_gpt and gpt_analyzer:
            search_result = []
            if enable_search:
                search_result = search_searxng(f"{cve_id}")

            logger.info("å¼€å§‹GPTåˆ†æ (GPTAnalyzer)")
            # ä½¿ç”¨æ–°çš„ GPTAnalyzer è¿›è¡Œåˆ†æ
            analyzer_result = gpt_analyzer.analyze(cve_info, search_result, code_prompt)

            if analyzer_result['success'] and analyzer_result['pass_quality_check']:
                logger.info("âœ“ GPTåˆ†ææˆåŠŸä¸”é€šè¿‡è´¨é‡æ£€æŸ¥")

                # ä½¿ç”¨CVEå¹´ä»½ä½œä¸ºç›®å½•ç»“æ„ (YYYY/)
                import re
                match = re.match(r'CVE-(\d{4})-\d+', cve_id)
                if match:
                    cve_year = match.group(1)
                else:
                    # å¦‚æœæ— æ³•è§£æCVEå¹´ä»½ï¼Œä½¿ç”¨å½“å‰å¹´ä»½
                    cve_year = datetime.now().strftime('%Y')
                    logger.warning(f"æ— æ³•è§£æCVEå¹´ä»½: {cve_id}, ä½¿ç”¨å½“å‰å¹´ä»½: {cve_year}")

                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(f"data/{cve_year}", exist_ok=True)

                # æ–°çš„æ–‡ä»¶è·¯å¾„
                filepath = f"data/{cve_year}/{cve_id}-{repo_full_name.replace('/', '_')}.md"

                # ç›´æ¥å†™å…¥ Markdown (GPTAnalyzer å·²ç»ç”Ÿæˆå¥½äº†)
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(analyzer_result['markdown'])

                # æ„å»º gpt_results ç”¨äºå‘åå…¼å®¹
                data = analyzer_result['data']
                gpt_results = {
                    'cve_id': cve_id,
                    'repo_name': repo_full_name,
                    'repo_url': repo_link,
                    'cve_url': f"https://nvd.nist.gov/vuln/detail/{cve_id}",
                    'action_log': 'æ–°å¢' if action_log == 'new' else 'æ›´æ–°',
                    'git_url': f"{get_config('GIT_URL')}/blob/main/{filepath}" if get_config('GIT_URL') else '',

                    # æ·»åŠ 15å­—æ®µåŸå§‹æ•°æ®
                    **data,

                    # å‘åå…¼å®¹æ˜ å°„ï¼ˆæ—§å­—æ®µå -> æ–°å­—æ®µåï¼‰
                    'type': data.get('vulnerability_type', ''),
                    'app': data.get('affected_product', ''),
                    'risk': data.get('severity', ''),
                    'version': data.get('affected_versions', ''),
                    'condition': data.get('exploit_conditions', ''),
                    'poc_available': f"{data.get('poc_quality', 0)}/10",
                    'poison': data.get('poisoning_risk', ''),
                }
                result['gpt'] = gpt_results
                logger.info(f'ç”Ÿæˆåˆ†ææŠ¥å‘Š: {filepath}')
            elif analyzer_result['success'] and not analyzer_result['pass_quality_check']:
                logger.warning(f"âœ— GPTåˆ†æå®Œæˆä½†æœªé€šè¿‡è´¨é‡æ£€æŸ¥: {'; '.join(analyzer_result['fail_reasons'])}")

                # è®°å½•è´¨é‡æ£€æŸ¥å¤±è´¥,å¯èƒ½è§¦å‘è‡ªåŠ¨æ‹‰é»‘
                if blacklist_manager:
                    data = analyzer_result.get('data', {})
                    quality_score = data.get('poc_quality')
                    poisoning_risk = data.get('poisoning_risk')

                    # æå–æ•°å€¼
                    import re
                    quality_val = None
                    risk_val = None

                    if quality_score is not None:
                        quality_match = re.search(r'(\d+)', str(quality_score))
                        if quality_match:
                            quality_val = int(quality_match.group(1))

                    if poisoning_risk is not None:
                        risk_match = re.search(r'(\d+)', str(poisoning_risk))
                        if risk_match:
                            risk_val = int(risk_match.group(1))

                    blacklist_manager.record_quality_check_failure(
                        repo,
                        quality_val,
                        risk_val,
                        analyzer_result['fail_reasons']
                    )
            else:
                logger.error(f"âœ— GPTåˆ†æå¤±è´¥: {analyzer_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                

        # è·å–æœ€æ–°commit SHA (å¦‚æœè¿˜æ²¡æœ‰)
        if latest_sha is None:
            latest_sha = get_latest_commit_sha(repo_link)
            if not latest_sha:
                logger.warning(f"æ— æ³•è·å–commit SHA: {repo_link}")

        # ä¿å­˜æˆ–æ›´æ–°ä»“åº“ä¿¡æ¯
        try:
            if action_log == 'update' and repo_data:
                # æ›´æ–°ç°æœ‰è®°å½•
                repo_data.repo_pushed_at = repo_pushed_at
                repo_data.latest_commit_sha = latest_sha
                repo_data.gpt_analysis = gpt_results
                repo_data.action_log = action_log
                repo_data.repo_data = repo
                repo_data.updated_at = datetime.now()
                logger.info(f"æ›´æ–°ä»“åº“ä¿¡æ¯æˆåŠŸ (SHA: {latest_sha[:8] if latest_sha else 'None'}...)")
            else:
                # æ–°å¢è®°å½•
                new_repo_data = Repository(
                    github_id=repo['id'],
                    cve_id=cve_id,
                    name=repo_name,
                    description=repo_description,
                    url=repo_link,
                    action_log=action_log,
                    repo_data=repo,
                    repo_pushed_at=repo_pushed_at,
                    latest_commit_sha=latest_sha,
                    gpt_analysis=gpt_results
                )
                engine.add(new_repo_data)
                logger.info(f"æ–°å¢ä»“åº“ä¿¡æ¯æˆåŠŸ (SHA: {latest_sha[:8] if latest_sha else 'None'}...)")

            engine.commit()
        except Exception as e:
            logger.error(f"ä¿å­˜ä»“åº“ä¿¡æ¯å¤±è´¥: {str(e)}")
            engine.rollback()
        

        # å‘é€é€šçŸ¥
        # åˆ¤æ–­ä»“åº“pushæ—¶é—´æ˜¯å¦ä¸ºä»Šå¤©,ç»Ÿä¸€æ—¶åŒº,å¦‚æœä¸ºå½“å¤©åˆ™å‘é€é€šçŸ¥ï¼Œå¦åˆ™åªå…¥åº“
        tz = timezone(timedelta(hours=8))  # UTC+8 for Asia/Shanghai
        today = datetime.now(tz).date()
        repo_date = datetime.strptime(repo_pushed_at, '%Y-%m-%dT%H:%M:%SZ').replace(tzinfo=timezone.utc).astimezone(tz).date()
        push_today = today == repo_date

        # åªæœ‰GPTåˆ†ææˆåŠŸä¸”å½“å¤©æ¨é€æ‰å‘é€é€šçŸ¥
        if enable_notify and push_today and gpt_results:
            # æ£€æŸ¥1: ä»“åº“æ›´æ–°æ¨é€å¼€å…³
            if action_log == 'update' and not enable_update_notify:
                logger.info(f"âŠ˜ ä»“åº“æ›´æ–°ä¸æ¨é€é€šçŸ¥ (ENABLE_UPDATE_NOTIFY=False): {repo_link}")
            # æ£€æŸ¥2: CVEå»é‡å¼€å…³
            elif enable_cve_dedup and cve_id in notified_cves_today:
                logger.info(f"âŠ˜ CVEä»Šæ—¥å·²æ¨é€,è·³è¿‡é‡å¤æ¨é€ (ENABLE_CVE_DEDUP=True): {cve_id}")
            # é€šè¿‡æ‰€æœ‰æ£€æŸ¥,å‘é€é€šçŸ¥
            else:
                logger.info(f"âœ“ å‘é€é£ä¹¦é€šçŸ¥: {cve_id} ({action_log})")
                send_webhook(result)
                # è®°å½•å·²æ¨é€çš„CVE
                if enable_cve_dedup:
                    notified_cves_today.add(cve_id)
                    logger.debug(f"å·²æ¨é€CVEåˆ—è¡¨æ›´æ–°: {len(notified_cves_today)} ä¸ªCVE")
        elif enable_notify and push_today and not gpt_results:
            logger.warning(f"GPTåˆ†æå¤±è´¥ï¼Œè·³è¿‡é€šçŸ¥æ¨é€: {repo_link}")
        return result

    except Exception as e:
        logger.error(f"å¤„ç†CVEå¼‚å¸¸: {str(e)}")
        logger.debug(traceback.format_exc())


def main():
    """
    ä¸»å‡½æ•°:æœç´¢å¹¶åˆ†æCVEæ¼æ´ä¿¡æ¯

    """
    try:
        query = "CVE-20"
        logger.info(f"å¼€å§‹æœç´¢CVE: {query}")

        # åˆå§‹åŒ–ä»Šæ—¥å·²æ¨é€CVEé›†åˆ(ç”¨äºå»é‡)
        notified_cves_today = set()
        logger.info(f"åˆå§‹åŒ–CVEå»é‡æœºåˆ¶: ENABLE_CVE_DEDUP={enable_cve_dedup}, ENABLE_UPDATE_NOTIFY={enable_update_notify}")

        # æœç´¢GitHubä»“åº“
        cve_list, repo_list = search_github(query)
        if not repo_list:
            logger.warning("æœªæ‰¾åˆ°ç›¸å…³ä»“åº“")
            return

        # è·å–æ•°æ®åº“è¿æ¥
        engine = get_db()
        
        # æ‰©å±•æœç´¢
        if enable_extended:
            logger.info("æ‰§è¡Œæ‰©å±•æœç´¢")
            for cve_id in cve_list:
                _, cve_items = search_github(cve_id)
                for item in cve_items:
                    if cve_id == item['cve_id']:
                        process_cve(cve_id, item['repo'], engine, notified_cves_today)
                time.sleep(10)
        else:
            # å¤„ç†æ¯ä¸ªä»“åº“
            for repo in repo_list:
                try:
                    cve_id = repo['cve_id']
                    logger.info(f"å¤„ç†CVE: {cve_id}")
                    result = process_cve(cve_id, repo['repo'], engine, notified_cves_today)
                    time.sleep(10)
                except Exception as e:
                    logger.error(f"å¤„ç†CVEå¼‚å¸¸: {str(e)} {repo}")
                    logger.debug(traceback.format_exc())
        logger.info("æœç´¢åˆ†æå®Œæˆ")

        # æ‰“å°æ¨é€ç»Ÿè®¡ä¿¡æ¯
        logger.info("=" * 50)
        logger.info(f"ğŸ“Š æœ¬æ¬¡è¿è¡Œæ¨é€ç»Ÿè®¡:")
        logger.info(f"  - å·²æ¨é€CVEæ•°é‡: {len(notified_cves_today)}")
        if notified_cves_today:
            logger.info(f"  - æ¨é€CVEåˆ—è¡¨: {', '.join(sorted(notified_cves_today))}")
        logger.info("=" * 50)

        # æ‰“å°é»‘åå•ç»Ÿè®¡ä¿¡æ¯
        if blacklist_manager:
            blacklist_manager.print_statistics()

    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¼‚å¸¸: {traceback.format_exc()}")
        sys.exit(1)

if __name__ == "__main__":
    logger.info(f"è¿è¡Œå‚æ•°:")
    logger.info(f"  è¿è¡Œæ¨¡å¼: {get_config('DEBUG')}")
    logger.info(f"  GPT å¼€å…³: {'å¯ç”¨' if get_config('ENABLE_GPT')==True else 'ç¦ç”¨'}")
    logger.info(f"  æœç´¢å¼€å…³: {'å¯ç”¨' if get_config('ENABLE_SEARCH')==True else 'ç¦ç”¨'}")
    logger.info(f"  æ‰©å±•æœç´¢å¼€å…³: {'å¯ç”¨' if get_config('ENABLE_EXTENDED')==True else 'ç¦ç”¨'}")
    logger.info(f"  æ›´æ–°æ£€æµ‹å¼€å…³: {'å¯ç”¨' if get_config('ENABLE_UPDATE_CHECK')==True else 'ç¦ç”¨'}")
    logger.info(f"  é€šçŸ¥å¼€å…³: {'å¯ç”¨' if get_config('ENABLE_NOTIFY')==True else 'ç¦ç”¨'}")
    logger.info(f"  é€šçŸ¥ç±»å‹: {get_config('NOTIFY_TYPE')}")
    main()
